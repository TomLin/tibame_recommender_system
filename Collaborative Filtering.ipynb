{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = pd.read_csv('the-movies-dataset/ratings_small.csv')\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rating_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort data frame by timestemp for splitting\n",
    "rating_df = rating_df.sort_values('timestamp')\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map user id and movie id to integer starting from 0 to N (num of users) and M (num of movies)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "user_encoder = LabelEncoder()\n",
    "movie_encoder = LabelEncoder()\n",
    "\n",
    "user_ids = user_encoder.fit_transform(rating_df.userId)\n",
    "movie_ids = movie_encoder.fit_transform(rating_df.movieId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(len(user_ids) * 0.8)\n",
    "train_user_ids = user_ids[:num_train]\n",
    "train_movie_ids = movie_ids[:num_train]\n",
    "train_ratings = rating_df.rating.values[:num_train]\n",
    "val_user_ids = user_ids[num_train:]\n",
    "val_movie_ids = movie_ids[num_train:]\n",
    "val_ratings = rating_df.rating.values[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set up user-movie matrix\n",
    "num_users = user_ids.max() + 1\n",
    "num_movies = movie_ids.max() + 1\n",
    "user2movie = np.zeros([num_users, num_movies])\n",
    "user2movie[train_user_ids, train_movie_ids] = train_ratings\n",
    "user2movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute similarity\n",
    "def pearson_correlation(x,y):\n",
    "    '''\n",
    "    Compute the pearson correlation for x and y.\n",
    "    args:\n",
    "        x: np.array\n",
    "        y: np.array\n",
    "    '''\n",
    "    \n",
    "    # set up filters for entries where x and y are both non zero\n",
    "    filt = (x != 0) * (y != 0)\n",
    "    \n",
    "    # compute mean for x and y\n",
    "    x_mean = x.sum() / x[x!=0].shape[0]\n",
    "    y_mean = y.sum() / y[y!=0].shape[0]\n",
    "    \n",
    "    # consider only entries based on the previous filter\n",
    "    x = x[filt]\n",
    "    y = y[filt]\n",
    "    \n",
    "    # compute correlation\n",
    "    corr = np.sum((x - x_mean) * (y-y_mean)) / (np.sum((y-y_mean) ** 2) * np.sum((x-x_mean) ** 2) ) ** 0.5\n",
    "    \n",
    "    return corr\n",
    "\n",
    "def compute_user_similarity_matrix(user2movie):\n",
    "    '''\n",
    "    Compute user similarity matrix\n",
    "    args:\n",
    "        user2movie: np.array, user-movie rating matrix\n",
    "    returns:\n",
    "        similarity_matrix: np.array, user 2 user similarity\n",
    "    \n",
    "    '''\n",
    "    # initialize similarity matrix\n",
    "    similarity_matrix = np.zeros([num_users, num_users])\n",
    "    \n",
    "    for i in range(len(user2movie)):\n",
    "        for j in range(i, len(user2movie)):\n",
    "            \n",
    "            # compute correlation\n",
    "            corr = pearson_correlation(user2movie[i],user2movie[j])\n",
    "            \n",
    "            # store correlation in matrix\n",
    "            similarity_matrix[i,j] = corr\n",
    "            similarity_matrix[j,i] = corr\n",
    "            \n",
    "    return similarity_matrix\n",
    "\n",
    "similarity_matrix = compute_user_similarity_matrix(user2movie)\n",
    "similarity_matrix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set similarity with itself to 0\n",
    "similarity_matrix[np.arange(num_users), np.arange(num_users)] = 0\n",
    "similarity_matrix[np.isnan(similarity_matrix)] = 0\n",
    "similarity_matrix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_ucf(user2movie, similarity_matrix):\n",
    "    '''\n",
    "    Compute prediction scores for all movies\n",
    "    args:\n",
    "        user2movie: np.array, user-movie rating matrix\n",
    "    returns:\n",
    "        scores: np.array, predicted scores of each video for the target user\n",
    "    '''\n",
    "\n",
    "    # compute mean rating yk, ignoring zero entries, shape:(num_users)\n",
    "    mean_ratings = np.sum(user2movie, axis=1) / (user2movie != 0 ).sum(axis=1)\n",
    "    \n",
    "    # compute ykj - yk, shape:(num_users, num_movies)\n",
    "    user2movie_diff = user2movie - np.expand_dims(mean_ratings, 1)\n",
    "    \n",
    "    # compute sum of similarities Î£simik, (num_users,)\n",
    "    sim_sum = np.sum(np.abs(similarity_matrix), axis=1)\n",
    "        \n",
    "    # don't sum the unknown entries, set them to 0        \n",
    "    user2movie_diff[np.where(user2movie == 0) ] = 0\n",
    "\n",
    "    # compute weighted sum of rating diff (num_users, num_movies)\n",
    "    weighted_sum = np.matmul(similarity_matrix, user2movie_diff) / np.expand_dims(sim_sum, 1)\n",
    "\n",
    "    # add weighted sum to mean ratings\n",
    "    scores =  weighted_sum + np.expand_dims(mean_ratings, 1)\n",
    "    \n",
    "    return  scores\n",
    "\n",
    "predictions = compute_ucf(user2movie, similarity_matrix) \n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit to https://gist.github.com/bwhite/3726239\n",
    "def dcg_at_k(r, k):\n",
    "    '''\n",
    "    Compute DCG\n",
    "    args:\n",
    "        r: np.array, to be evaluated\n",
    "        k: int, number of entries to be considered\n",
    "    \n",
    "    returns:\n",
    "        dcg: float, computed dcg\n",
    "        \n",
    "    '''\n",
    "    r = r[:k]\n",
    "    dcg = np.sum(r / np.log2(np.arange(2, len(r) + 2)))\n",
    "    return dcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(r, k, method=0):\n",
    "    '''\n",
    "    Compute NDCG\n",
    "    args:\n",
    "        r: np.array, to be evaluated\n",
    "        k: int, number of entries to be considered\n",
    "    \n",
    "    returns:\n",
    "        dcg: float, computed ndcg\n",
    "        \n",
    "    '''\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k)\n",
    "\n",
    "    return dcg_at_k(r, k) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compute average ndcg for all users\n",
    "def evaluate_prediction(predictions):\n",
    "    '''\n",
    "    Return the average ndcg for each users\n",
    "    args:\n",
    "        predictions: np.array user-item predictions\n",
    "    returns:\n",
    "        ndcg: float, computed NDCG\n",
    "    '''\n",
    "    ndcgs = []\n",
    "    # iterate\n",
    "    for target_user in np.unique(val_user_ids):\n",
    "        # get movie ids and ratings associated with the target user.\n",
    "        target_val_movie_ids = val_movie_ids[val_user_ids == target_user] \n",
    "        target_val_ratings = val_ratings[val_user_ids == target_user] \n",
    "        \n",
    "        # compute ndcg for this user\n",
    "        ndcg = ndcg_at_k(target_val_ratings[np.argsort(-predictions[target_user][target_val_movie_ids])], k=30)\n",
    "        ndcgs.append(ndcg)\n",
    "    ndcg = np.mean(ndcgs)\n",
    "    return ndcg\n",
    "evaluate_prediction(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_item_similarity_matrix(user2movie):\n",
    "    '''\n",
    "    Compute item similarity matrix\n",
    "    args:\n",
    "        user2movie: np.array, user-movie rating matrix\n",
    "    returns:\n",
    "        similarity_matrix: np.array, item-item similarity\n",
    "    \n",
    "    '''\n",
    "    # compute mean for each user\n",
    "    x_mean = user2movie.sum(axis=0) / (user2movie!=0).sum(axis=0)\n",
    "    \n",
    "    # set up filter for zero entries\n",
    "    filt = (user2movie==0)\n",
    "    \n",
    "    # compute rating difference\n",
    "    rating_diff = user2movie - np.expand_dims(x_mean, axis=0)\n",
    "    rating_diff[filt] = 0\n",
    "\n",
    "    # compute similarity\n",
    "    similarity_matrix = np.matmul(rating_diff.T, rating_diff) / (np.matmul(rating_diff.T  ** 2, (rating_diff != 0)) * np.matmul(rating_diff.T  ** 2, (rating_diff != 0)).T) ** 0.5\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "similarity_matrix = compute_item_similarity_matrix(user2movie)\n",
    "similarity_matrix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set similarity with itself to 0\n",
    "similarity_matrix[np.arange(num_movies), np.arange(num_movies)] = 0\n",
    "similarity_matrix[np.isnan(similarity_matrix)] = 0\n",
    "similarity_matrix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_icf(user2movie, similarity_matrix):\n",
    "    '''\n",
    "    Compute prediction scores for all movies with item-based CF.\n",
    "    args:\n",
    "        user2movie: np.array, user-movie rating matrix\n",
    "    returns:\n",
    "        scores: np.array, predicted scores of each video for the target user\n",
    "    '''\n",
    "\n",
    "    # compute mean rating yk, ignoring zero entries, shape:(num_movies)\n",
    "    mean_ratings = np.sum(user2movie, axis=0) / (user2movie != 0 ).sum(axis=0)\n",
    "    \n",
    "    # compute ykj - yk, shape:(num_users, num_movies)\n",
    "    user2movie_diff = user2movie - np.expand_dims(mean_ratings, axis=0)\n",
    "    \n",
    "    # compute sum of similarities Î£simik, (num_movies,)\n",
    "    sim_sum = np.sum(np.abs(similarity_matrix), axis=1)\n",
    "    \n",
    "    # don't sum the unknown entries, set them to 0\n",
    "    user2movie_diff[np.where(user2movie == 0) ] = 0\n",
    "    \n",
    "    # compute weighted sum of rating diff (num_users, num_movies)\n",
    "    weighted_sum = np.matmul(user2movie_diff, similarity_matrix) / np.expand_dims(sim_sum, axis=0)\n",
    "\n",
    "    # add weighted sum to mean ratings\n",
    "    scores =  weighted_sum + np.expand_dims(mean_ratings, 0)\n",
    "    \n",
    "    return  scores\n",
    "\n",
    "predictions = compute_icf(user2movie, similarity_matrix) \n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_prediction(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
