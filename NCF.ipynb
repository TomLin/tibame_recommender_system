{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = pd.read_csv('the-movies-dataset/ratings_small.csv')\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52635</th>\n",
       "      <td>383</td>\n",
       "      <td>21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>789652009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52641</th>\n",
       "      <td>383</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>789652009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52684</th>\n",
       "      <td>383</td>\n",
       "      <td>1079</td>\n",
       "      <td>3.0</td>\n",
       "      <td>789652009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56907</th>\n",
       "      <td>409</td>\n",
       "      <td>21</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828212412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56909</th>\n",
       "      <td>409</td>\n",
       "      <td>25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>828212412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating  timestamp\n",
       "52635     383       21     3.0  789652009\n",
       "52641     383       47     5.0  789652009\n",
       "52684     383     1079     3.0  789652009\n",
       "56907     409       21     5.0  828212412\n",
       "56909     409       25     4.0  828212412"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort data frame by timestemp for splitting\n",
    "rating_df = rating_df.sort_values('timestamp')\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map user id and movie id to integer starting from 0 to N (num of users) and M (num of movies)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "user_encoder = LabelEncoder()\n",
    "movie_encoder = LabelEncoder()\n",
    "\n",
    "user_ids = user_encoder.fit_transform(rating_df.userId)\n",
    "movie_ids = movie_encoder.fit_transform(rating_df.movieId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / val split\n",
    "num_train = int(len(user_ids) * 0.8)\n",
    "train_user_ids = user_ids[:num_train]\n",
    "train_movie_ids = movie_ids[:num_train]\n",
    "train_ratings = rating_df.rating.values[:num_train]\n",
    "val_user_ids = user_ids[num_train:]\n",
    "val_movie_ids = movie_ids[num_train:]\n",
    "val_ratings = rating_df.rating.values[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users= user_ids.max()+1\n",
    "num_movies = movie_ids.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize ratings\n",
    "train_ratings /= 5\n",
    "val_ratings /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit to https://gist.github.com/bwhite/3726239\n",
    "def dcg_at_k(r, k):\n",
    "    '''\n",
    "    Compute DCG\n",
    "    args:\n",
    "        r: np.array, to be evaluated\n",
    "        k: int, number of entries to be considered\n",
    "    \n",
    "    returns:\n",
    "        dcg: float, computed dcg\n",
    "        \n",
    "    '''\n",
    "    r = r[:k]\n",
    "    dcg = np.sum(r / np.log2(np.arange(2, len(r) + 2)))\n",
    "    return dcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(r, k, method=0):\n",
    "    '''\n",
    "    Compute NDCG\n",
    "    args:\n",
    "        r: np.array, to be evaluated\n",
    "        k: int, number of entries to be considered\n",
    "    \n",
    "    returns:\n",
    "        dcg: float, computed ndcg\n",
    "        \n",
    "    '''\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k)\n",
    "\n",
    "    return dcg_at_k(r, k) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute average ndcg for all users\n",
    "def evaluate_prediction(predictions):\n",
    "    '''\n",
    "    Return the average ndcg for each users\n",
    "    args:\n",
    "        predictions: np.array user-item predictions\n",
    "    returns:\n",
    "        ndcg: float, computed NDCG\n",
    "    '''\n",
    "    ndcgs = []\n",
    "    # iterate\n",
    "    for target_user in np.unique(val_user_ids):\n",
    "        # get movie ids and ratings associated with the target user.\n",
    "        target_val_movie_ids = val_movie_ids[val_user_ids == target_user] \n",
    "        target_val_ratings = val_ratings[val_user_ids == target_user] \n",
    "        \n",
    "        # compute ndcg for this user\n",
    "        ndcg = ndcg_at_k(target_val_ratings[np.argsort(-predictions[val_user_ids == target_user])], k=30)\n",
    "        ndcgs.append(ndcg)\n",
    "#         print(np.argsort(-predictions[val_user_ids == target_user]))\n",
    "    ndcg = np.mean(ndcgs)\n",
    "    return ndcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steevehuang/miniconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/steevehuang/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/steevehuang/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/steevehuang/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/steevehuang/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/steevehuang/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/steevehuang/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, concatenate, Flatten, Activation, Add, Dropout, Multiply\n",
    "from keras.optimizers import Adam\n",
    "def get_mf_model():\n",
    "    # user input\n",
    "    user_inp = Input((1,))\n",
    "    user_hidden = Embedding(input_dim=num_users, output_dim=50)(user_inp)\n",
    "    user_hidden = Flatten()(user_hidden)\n",
    "    \n",
    "    # item input\n",
    "    item_inp = Input((1,))\n",
    "    item_hidden = Embedding(input_dim=num_movies, output_dim=50)(item_inp)\n",
    "    item_hidden = Flatten()(item_hidden)\n",
    "    \n",
    "    # element-wise multiplication\n",
    "    hidden = Multiply()([user_hidden, item_hidden])\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid')(hidden)\n",
    "    \n",
    "    model = Model(inputs=[user_inp, item_inp], outputs=output)\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=0.0005))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        33550       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 50)        453300      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 50)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 50)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 50)           0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            51          multiply_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 486,901\n",
      "Trainable params: 486,901\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# init mf model\n",
    "model = get_mf_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80003 samples, validate on 20001 samples\n",
      "Epoch 1/50\n",
      "80003/80003 [==============================] - 3s 34us/step - loss: 0.0745 - val_loss: 0.0657\n",
      "Epoch 2/50\n",
      "80003/80003 [==============================] - 2s 28us/step - loss: 0.0500 - val_loss: 0.0553\n",
      "Epoch 3/50\n",
      "80003/80003 [==============================] - 2s 29us/step - loss: 0.0338 - val_loss: 0.0539\n",
      "Epoch 4/50\n",
      "80003/80003 [==============================] - 2s 31us/step - loss: 0.0284 - val_loss: 0.0543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x127d74ba8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "# early stopping wait for 1 epoch\n",
    "callbacks = [EarlyStopping(patience=1)]\n",
    "\n",
    "# train for 50 epochs\n",
    "model.fit([train_user_ids, train_movie_ids], train_ratings,\\\n",
    "          validation_data=([val_user_ids, val_movie_ids], val_ratings), epochs=50, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348814003225187"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction & evalutation\n",
    "predictions = model.predict([val_user_ids, val_movie_ids])\n",
    "evaluate_prediction(predictions[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 64)        42944       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 64)        580224      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 64)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 64)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128)          0           flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            65          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 648,001\n",
      "Trainable params: 648,001\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_mlp_model():\n",
    "    user_inp = Input((1,))\n",
    "    user_hidden = Embedding(input_dim=num_users, output_dim=64)(user_inp)\n",
    "    user_hidden = Flatten()(user_hidden)\n",
    "    \n",
    "    item_inp = Input((1,))\n",
    "    item_hidden = Embedding(input_dim=num_movies, output_dim=64)(item_inp)\n",
    "    item_hidden = Flatten()(item_hidden)\n",
    "    \n",
    "    hidden = concatenate([user_hidden, item_hidden])\n",
    "    hidden = Dense(128, activation='relu')(hidden)\n",
    "    hidden = Dropout(0.2)(hidden)\n",
    "    hidden = Dense(64, activation='relu')(hidden)    \n",
    "    hidden = Dropout(0.2)(hidden)    \n",
    "    output = Dense(1, activation='sigmoid')(hidden)\n",
    "    \n",
    "    model = Model(inputs=[user_inp, item_inp], outputs=output)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "model = get_mlp_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80003 samples, validate on 20001 samples\n",
      "Epoch 1/50\n",
      "80003/80003 [==============================] - 4s 51us/step - loss: 0.0364 - val_loss: 0.0419\n",
      "Epoch 2/50\n",
      "80003/80003 [==============================] - 4s 48us/step - loss: 0.0301 - val_loss: 0.0422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12805ca58>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train for 50 epochs\n",
    "model.fit([train_user_ids, train_movie_ids], train_ratings,\\\n",
    "          validation_data=([val_user_ids, val_movie_ids], val_ratings), epochs=50, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8752340572923161"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction & evalutation\n",
    "predictions = model.predict([val_user_ids, val_movie_ids])\n",
    "evaluate_prediction(predictions[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 64)        42944       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 64)        580224      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 64)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 64)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128)          0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16512       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 64)           0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           8256        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128)          0           multiply_2[0][0]                 \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            129         concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 648,065\n",
      "Trainable params: 648,065\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_ncf_model():\n",
    "    user_inp = Input((1,))\n",
    "    user_hidden = Embedding(input_dim=num_users, output_dim=64)(user_inp)\n",
    "    user_hidden = Flatten()(user_hidden)\n",
    "    \n",
    "    item_inp = Input((1,))\n",
    "    item_hidden = Embedding(input_dim=num_movies, output_dim=64)(item_inp)\n",
    "    item_hidden = Flatten()(item_hidden)\n",
    "    \n",
    "    # element-wise multiplication\n",
    "    mf_output = Multiply()([user_hidden, item_hidden])\n",
    "    \n",
    "    hidden = concatenate([user_hidden, item_hidden])\n",
    "    hidden = Dense(128, activation='relu')(hidden)\n",
    "    hidden = Dropout(0.2)(hidden)\n",
    "    mlp_output = Dense(64, activation='relu')(hidden)    \n",
    "\n",
    "    \n",
    "    output = concatenate([mf_output, mlp_output])\n",
    "    output = Dense(1, activation='sigmoid')(output)\n",
    "    \n",
    "    model = Model(inputs=[user_inp, item_inp], outputs=output)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "model = get_ncf_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80003 samples, validate on 20001 samples\n",
      "Epoch 1/50\n",
      "80003/80003 [==============================] - 4s 51us/step - loss: 0.0360 - val_loss: 0.0417\n",
      "Epoch 2/50\n",
      "80003/80003 [==============================] - 4s 45us/step - loss: 0.0298 - val_loss: 0.0418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12935a978>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train for 50 epochs\n",
    "model.fit([train_user_ids, train_movie_ids], train_ratings,\\\n",
    "          validation_data=([val_user_ids, val_movie_ids], val_ratings), epochs=50, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875748165354793"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction & evalutation\n",
    "predictions = model.predict([val_user_ids, val_movie_ids])\n",
    "evaluate_prediction(predictions[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
